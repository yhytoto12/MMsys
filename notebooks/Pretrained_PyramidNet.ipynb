{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretrained PyramidNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLPnweNg-Hyw",
        "outputId": "65c53f8d-5265-47f4-82ca-bf0faafe38c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connecting and Mounting to the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/pyramid_for_cifar.pth'"
      ],
      "metadata": {
        "id": "oqq_WYKo-VgZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "MCP_xVjy30ut"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyramidNet"
      ],
      "metadata": {
        "id": "ZZIflLG8_nMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "#from math import round\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    outchannel_ratio = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)        \n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)        \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn3(out)\n",
        "       \n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "            featuremap_size = shortcut.size()[2:4]\n",
        "        else:\n",
        "            shortcut = x\n",
        "            featuremap_size = out.size()[2:4]\n",
        "\n",
        "        batch_size = out.size()[0]\n",
        "        residual_channel = out.size()[1]\n",
        "        shortcut_channel = shortcut.size()[1]\n",
        "\n",
        "        if residual_channel != shortcut_channel:\n",
        "            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n",
        "            out += torch.cat((shortcut, padding), 1)\n",
        "        else:\n",
        "            out += shortcut \n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    outchannel_ratio = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, (planes*1), kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d((planes*1))\n",
        "        self.conv3 = nn.Conv2d((planes*1), planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)\n",
        "        \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        " \n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        out = self.bn4(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "            featuremap_size = shortcut.size()[2:4]\n",
        "        else:\n",
        "            shortcut = x\n",
        "            featuremap_size = out.size()[2:4]\n",
        "\n",
        "        batch_size = out.size()[0]\n",
        "        residual_channel = out.size()[1]\n",
        "        shortcut_channel = shortcut.size()[1]\n",
        "\n",
        "        if residual_channel != shortcut_channel:\n",
        "            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n",
        "            out += torch.cat((shortcut, padding), 1)\n",
        "        else:\n",
        "            out += shortcut \n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class PyramidNet(nn.Module):\n",
        "        \n",
        "    def __init__(self, dataset, depth, alpha, num_classes, bottleneck=False):\n",
        "        super(PyramidNet, self).__init__()   \t\n",
        "        self.dataset = dataset\n",
        "        if self.dataset.startswith('cifar'):\n",
        "            self.inplanes = 16\n",
        "            if bottleneck == True:\n",
        "                n = int((depth - 2) / 9)\n",
        "                block = Bottleneck\n",
        "            else:\n",
        "                n = int((depth - 2) / 6)\n",
        "                block = BasicBlock\n",
        "\n",
        "            self.addrate = alpha / (3*n*1.0)\n",
        "\n",
        "            self.input_featuremap_dim = self.inplanes\n",
        "            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
        "\n",
        "            self.featuremap_dim = self.input_featuremap_dim \n",
        "            self.layer1 = self.pyramidal_make_layer(block, n)\n",
        "            self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\n",
        "            self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\n",
        "\n",
        "            self.final_featuremap_dim = self.input_featuremap_dim\n",
        "            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n",
        "            self.relu_final = nn.ReLU(inplace=True)\n",
        "            self.avgpool = nn.AvgPool2d(8)\n",
        "            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
        "\n",
        "        elif dataset == 'imagenet':\n",
        "            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n",
        "            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n",
        "\n",
        "            if layers.get(depth) is None:\n",
        "                if bottleneck == True:\n",
        "                    blocks[depth] = Bottleneck\n",
        "                    temp_cfg = int((depth-2)/12)\n",
        "                else:\n",
        "                    blocks[depth] = BasicBlock\n",
        "                    temp_cfg = int((depth-2)/8)\n",
        "\n",
        "                layers[depth]= [temp_cfg, temp_cfg, temp_cfg, temp_cfg]\n",
        "                print('=> the layer configuration for each stage is set to', layers[depth])\n",
        "\n",
        "            self.inplanes = 64            \n",
        "            self.addrate = alpha / (sum(layers[depth])*1.0)\n",
        "\n",
        "            self.input_featuremap_dim = self.inplanes\n",
        "            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "            self.featuremap_dim = self.input_featuremap_dim \n",
        "            self.layer1 = self.pyramidal_make_layer(blocks[depth], layers[depth][0])\n",
        "            self.layer2 = self.pyramidal_make_layer(blocks[depth], layers[depth][1], stride=2)\n",
        "            self.layer3 = self.pyramidal_make_layer(blocks[depth], layers[depth][2], stride=2)\n",
        "            self.layer4 = self.pyramidal_make_layer(blocks[depth], layers[depth][3], stride=2)\n",
        "\n",
        "            self.final_featuremap_dim = self.input_featuremap_dim\n",
        "            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n",
        "            self.relu_final = nn.ReLU(inplace=True)\n",
        "            self.avgpool = nn.AvgPool2d(7) \n",
        "            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def pyramidal_make_layer(self, block, block_depth, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1: # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n",
        "            downsample = nn.AvgPool2d((2,2), stride = (2, 2), ceil_mode=True)\n",
        "\n",
        "        layers = []\n",
        "        self.featuremap_dim = self.featuremap_dim + self.addrate\n",
        "        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\n",
        "        for i in range(1, block_depth):\n",
        "            temp_featuremap_dim = self.featuremap_dim + self.addrate\n",
        "            layers.append(block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\n",
        "            self.featuremap_dim  = temp_featuremap_dim\n",
        "        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.dataset == 'cifar10' or self.dataset == 'cifar100':\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            \n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "\n",
        "            x = self.bn_final(x)\n",
        "            x = self.relu_final(x)\n",
        "            x = self.avgpool(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "\n",
        "        elif self.dataset == 'imagenet':\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "            x = self.layer4(x)\n",
        "\n",
        "            x = self.bn_final(x)\n",
        "            x = self.relu_final(x)\n",
        "            x = self.avgpool(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "    \n",
        "        return x"
      ],
      "metadata": {
        "id": "5o4-UxnS-3oa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load state dict using .pth file"
      ],
      "metadata": {
        "id": "tbTjUpV__r9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PyramidNet('cifar10', 32, 300, 10, True)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3O5NQgv-b07",
        "outputId": "bbc818df-4925-4ed2-ef35-8a41ebc6a5a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyramidNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(16, 49, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(49, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(49, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(196, 83, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(83, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(83, 332, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(332, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (bn1): BatchNorm2d(332, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(332, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(116, 464, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (bn1): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(464, 149, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(149, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(149, 149, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(149, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(149, 596, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(596, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (bn1): BatchNorm2d(596, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(596, 183, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(183, 183, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(183, 732, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(732, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (bn1): BatchNorm2d(732, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(732, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(216, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(864, 249, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(249, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(249, 249, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(249, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(249, 996, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(996, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (bn1): BatchNorm2d(996, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(996, 283, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(283, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(283, 283, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(283, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(283, 1132, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(1132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (bn1): BatchNorm2d(1132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(1132, 316, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(316, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(316, 316, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(316, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(316, 1264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(1264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (bn_final): BatchNorm2d(1264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu_final): ReLU(inplace=True)\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "  (fc): Linear(in_features=1264, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the Test Loader"
      ],
      "metadata": {
        "id": "mmg5maV5ABS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VwZV6fVAAoZ",
        "outputId": "9b356e3b-f9c3-4011-fd55-6c4e67804087"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "2bWCGB6cBHcM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "rJXXmBOz_1Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "qcJR-kr0_lu1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irHtOsKd_253",
        "outputId": "b5fa1694-0915-4997-eb73-0677e1dd3c10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyramidNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(16, 49, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(49, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(49, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(196, 83, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(83, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(83, 332, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(332, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (bn1): BatchNorm2d(332, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(332, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(116, 464, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (bn1): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(464, 149, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(149, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(149, 149, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(149, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(149, 596, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(596, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (bn1): BatchNorm2d(596, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(596, 183, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(183, 183, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(183, 732, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(732, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (bn1): BatchNorm2d(732, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(732, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(216, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(864, 249, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(249, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(249, 249, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(249, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(249, 996, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(996, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (bn1): BatchNorm2d(996, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(996, 283, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(283, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(283, 283, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(283, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(283, 1132, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(1132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (bn1): BatchNorm2d(1132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(1132, 316, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(316, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(316, 316, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(316, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(316, 1264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn4): BatchNorm2d(1264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (bn_final): BatchNorm2d(1264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu_final): ReLU(inplace=True)\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "  (fc): Linear(in_features=1264, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {round(100*correct/total, 2)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r67NI3B_88v",
        "outputId": "0a8bb265-a9e3-46ed-be39-aa07435a6721"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 89.95 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwBt_dvzA4Y9",
        "outputId": "bc16ed7c-1752-4692-88e3-8255a681f7fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: plane is 84.2 %\n",
            "Accuracy for class: car   is 97.4 %\n",
            "Accuracy for class: bird  is 90.3 %\n",
            "Accuracy for class: cat   is 81.1 %\n",
            "Accuracy for class: deer  is 85.9 %\n",
            "Accuracy for class: dog   is 91.0 %\n",
            "Accuracy for class: frog  is 91.6 %\n",
            "Accuracy for class: horse is 91.3 %\n",
            "Accuracy for class: ship  is 92.6 %\n",
            "Accuracy for class: truck is 94.1 %\n"
          ]
        }
      ]
    }
  ]
}